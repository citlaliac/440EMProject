{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mainurl = 'https://www.sec.gov/Archives/edgar/full-index/'\n",
    "r=requests.get(mainurl)\n",
    "data=r.text\n",
    "soup = BeautifulSoup(data, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = []\n",
    "i = 1\n",
    "while i < 200:\n",
    "    years.append((str(i+1993)) + '/')\n",
    "    i += 1\n",
    "    \n",
    "yearHyperlinks = []\n",
    "newUrls = []\n",
    "\n",
    "for i in soup.find_all('a'):\n",
    "    if (i.text + '/') in years:\n",
    "        yearHyperlinks.append(i)\n",
    "\n",
    "for i in yearHyperlinks:\n",
    "    newUrls.append(mainurl + str(i.get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quarters = ['QTR1','QTR2','QTR3','QTR4']\n",
    "newNewUrls = []\n",
    "\n",
    "for url in newUrls:\n",
    "    r=requests.get(url)\n",
    "    data=r.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    for tag in soup.find_all('a'):\n",
    "        if tag.text in quarters:\n",
    "            newNewUrls.append(url + str(tag.get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1amount of URLs has been processed\n",
      "2amount of URLs has been processed\n",
      "3amount of URLs has been processed\n",
      "4amount of URLs has been processed\n",
      "5amount of URLs has been processed\n",
      "6amount of URLs has been processed\n",
      "7amount of URLs has been processed\n",
      "8amount of URLs has been processed\n",
      "9amount of URLs has been processed\n",
      "10amount of URLs has been processed\n",
      "11amount of URLs has been processed\n",
      "12amount of URLs has been processed\n",
      "13amount of URLs has been processed\n",
      "14amount of URLs has been processed\n",
      "15amount of URLs has been processed\n",
      "16amount of URLs has been processed\n",
      "17amount of URLs has been processed\n",
      "18amount of URLs has been processed\n",
      "19amount of URLs has been processed\n",
      "20amount of URLs has been processed\n",
      "21amount of URLs has been processed\n",
      "22amount of URLs has been processed\n",
      "23amount of URLs has been processed\n",
      "24amount of URLs has been processed\n",
      "25amount of URLs has been processed\n",
      "26amount of URLs has been processed\n",
      "27amount of URLs has been processed\n",
      "28amount of URLs has been processed\n",
      "29amount of URLs has been processed\n",
      "30amount of URLs has been processed\n",
      "31amount of URLs has been processed\n",
      "32amount of URLs has been processed\n",
      "33amount of URLs has been processed\n",
      "34amount of URLs has been processed\n",
      "35amount of URLs has been processed\n",
      "36amount of URLs has been processed\n",
      "37amount of URLs has been processed\n",
      "38amount of URLs has been processed\n",
      "39amount of URLs has been processed\n",
      "40amount of URLs has been processed\n",
      "41amount of URLs has been processed\n",
      "42amount of URLs has been processed\n",
      "43amount of URLs has been processed\n",
      "44amount of URLs has been processed\n",
      "45amount of URLs has been processed\n",
      "46amount of URLs has been processed\n",
      "47amount of URLs has been processed\n",
      "48amount of URLs has been processed\n",
      "49amount of URLs has been processed\n",
      "50amount of URLs has been processed\n",
      "51amount of URLs has been processed\n",
      "52amount of URLs has been processed\n",
      "53amount of URLs has been processed\n",
      "54amount of URLs has been processed\n",
      "55amount of URLs has been processed\n",
      "56amount of URLs has been processed\n",
      "57amount of URLs has been processed\n",
      "58amount of URLs has been processed\n",
      "59amount of URLs has been processed\n",
      "60amount of URLs has been processed\n",
      "61amount of URLs has been processed\n",
      "62amount of URLs has been processed\n",
      "63amount of URLs has been processed\n",
      "64amount of URLs has been processed\n",
      "65amount of URLs has been processed\n",
      "66amount of URLs has been processed\n",
      "67amount of URLs has been processed\n",
      "68amount of URLs has been processed\n",
      "69amount of URLs has been processed\n",
      "70amount of URLs has been processed\n",
      "71amount of URLs has been processed\n",
      "72amount of URLs has been processed\n",
      "73amount of URLs has been processed\n",
      "74amount of URLs has been processed\n",
      "75amount of URLs has been processed\n",
      "76amount of URLs has been processed\n",
      "77amount of URLs has been processed\n",
      "78amount of URLs has been processed\n",
      "79amount of URLs has been processed\n",
      "80amount of URLs has been processed\n",
      "81amount of URLs has been processed\n",
      "82amount of URLs has been processed\n",
      "83amount of URLs has been processed\n",
      "84amount of URLs has been processed\n",
      "85amount of URLs has been processed\n",
      "86amount of URLs has been processed\n",
      "87amount of URLs has been processed\n",
      "88amount of URLs has been processed\n",
      "89amount of URLs has been processed\n",
      "90amount of URLs has been processed\n",
      "91amount of URLs has been processed\n",
      "92amount of URLs has been processed\n",
      "93amount of URLs has been processed\n",
      "94amount of URLs has been processed\n",
      "95amount of URLs has been processed\n",
      "96amount of URLs has been processed\n",
      "97amount of URLs has been processed\n"
     ]
    }
   ],
   "source": [
    "errorCount = 1\n",
    "while True:\n",
    "    try:\n",
    "        from io import BytesIO\n",
    "        from urllib.request import urlopen\n",
    "        from zipfile import ZipFile\n",
    "        totalData = pd.DataFrame()\n",
    "        allTheCorrectData = pd.DataFrame()\n",
    "        countOfUrls = 1\n",
    "\n",
    "\n",
    "        master = \"master.zip\"\n",
    "        for url in newNewUrls:\n",
    "            r=requests.get(url)\n",
    "            data=r.text\n",
    "            soup = BeautifulSoup(data, 'lxml')\n",
    "            for tag in soup.find_all('a'):\n",
    "                if tag.text == master:\n",
    "                    zipurl = url + tag.text\n",
    "                    with urlopen(zipurl) as zipresp:\n",
    "                        with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                            zfile.extractall('C:\\\\Users\\\\Cody\\\\Documents\\\\2017-2018 School Year\\\\Semester 2\\\\CIS440\\\\index files')\n",
    "                            zfile.close()\n",
    "            os.chdir('C:\\\\Users\\\\Cody\\\\Documents\\\\2017-2018 School Year\\\\Semester 2\\\\CIS440\\\\index files')\n",
    "            with open('master.idx', 'rb') as f:\n",
    "                data = f.read()\n",
    "\n",
    "            data =data.decode(\"utf-8\", errors='replace')\n",
    "            data = data.split('|')\n",
    "            data = data[1:]\n",
    "\n",
    "            companies = []\n",
    "            forms = []\n",
    "            dateFiled = []\n",
    "            hyperLink = []\n",
    "\n",
    "            count = 0\n",
    "            while count < len(data):\n",
    "                companies.append(data[count])\n",
    "                count+=4\n",
    "\n",
    "            count = 1\n",
    "            while count < len(data):\n",
    "                forms.append(data[count])\n",
    "                count+=4\n",
    "\n",
    "            count = 2\n",
    "            while count < len(data):\n",
    "                dateFiled.append(data[count])\n",
    "                count+=4\n",
    "\n",
    "            count = 3\n",
    "            while count < len(data):\n",
    "                hyperLink.append(data[count])\n",
    "                count+=4\n",
    "\n",
    "            masterData = pd.DataFrame({'Company Names' : companies, 'Forms':forms,'Date Filed':dateFiled,'hyperLink':hyperLink})\n",
    "            masterData = masterData.iloc[1:,]\n",
    "            correctData = masterData[masterData['Forms'] == '10-K']                                          \n",
    "            totalData = totalData.append(masterData)\n",
    "            allTheCorrectData = allTheCorrectData.append(correctData)                 \n",
    "            print(str(countOfUrls) + 'amount of URLs has been processed')\n",
    "            countOfUrls += 1\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        print(\"There was an error this is number \" + str(errorCount))\n",
    "        errorCount += 1\n",
    "        continue\n",
    "    break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctList = []\n",
    "for i in allTheCorrectData['hyperLink']:\n",
    "    correctList.append(i.split('\\r')[0])\n",
    "dataUrls = []\n",
    "for i in correctList:\n",
    "    dataUrls.append('https://www.sec.gov/Archives/' + i)\n",
    "    \n",
    "allTheCorrectData['hyperLink'] = dataUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = allTheCorrectData[allTheCorrectData['Date Filed'] > '2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = ['ESPP','espp','Employee Stock Purchase Plan','lower of','closing period','discount','stock price on the purchase date',\n",
    "            '90% of the market value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Cody\\\\Documents\\\\2017-2018 School Year\\\\Semester 2\\\\CIS440')\n",
    "# allTheCorrectData.to_csv('List of Company Documents.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'List of Company Documents.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f05810393684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallTheCorrectData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'List of Company Documents.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallTheCorrectData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mallTheCorrectData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date Filed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;34m'2017-01-01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'List of Company Documents.csv' does not exist"
     ]
    }
   ],
   "source": [
    "allTheCorrectData = pd.read_csv('List of Company Documents.csv')\n",
    "x = allTheCorrectData[allTheCorrectData['Date Filed'] > '2017-01-01']\n",
    "x[0:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNH Equipment Trust 2013-C has a keyword which is discount\n",
      "MYR GROUP INC. has a keyword which is discount\n",
      "CASS INFORMATION SYSTEMS INC has a keyword which is discount\n",
      "OCEANEERING INTERNATIONAL INC has a keyword which is discount\n",
      "NEWELL BRANDS INC has a keyword which is discount\n",
      "SUPERCONDUCTOR TECHNOLOGIES INC has a keyword which is discount\n",
      "Capital Financial Holdings, Inc has a keyword which is discount\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-25bcfc64439e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mtextList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mcompanyName\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Company Names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mcount1\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Company Names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' has a keyword which is '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1749\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "textList = []\n",
    "companyName = []\n",
    "count2 = 0\n",
    "count1 = 0\n",
    "index = 0\n",
    "for url in x['hyperLink']:\n",
    "    r=requests.get(url)\n",
    "    data=r.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    keywordTF = False\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        for z in keywords:\n",
    "            if z in paragraph.text:\n",
    "                textList.append(paragraph.text)\n",
    "                companyName.append(x['Company Names'].iloc[index])\n",
    "                count1 +=1\n",
    "                print(x['Company Names'].iloc[index] + ' has a keyword which is ' + z)\n",
    "                index +=1\n",
    "            else:\n",
    "                count2 +=1\n",
    "                index += 1\n",
    "\n",
    "    \n",
    "    \n",
    "print(str(count2) + ' out of ' + str(len(x['hyperLink'])) + ' dont have a keyword')\n",
    "print(str(count1) + ' have keywords out of ' + str(len(x['hyperLink'])) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p style=\"border: none; color: black; font-family: 'Times New Roman', serif; font-size: 11.0pt; margin: 0in; margin-bottom: .0001pt; margin-left: 45.0pt; text-indent: -45.0pt\">10.40       Henry Schein, Inc. 2004 Employee Stock Purchase Plan, effective as of May 25, 2004. (Incorporated by reference to Exhibit D to our definitive 2004 Proxy Statement on Schedule 14A, filed on April 27, 2004.)**</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">The following table\n",
      "provides our equity compensation plan information as of December 31, 2016. Under these plans, our common stock may be issued upon\n",
      "the exercise of options and purchases under our Employee Stock Purchase Plan (“ESPP”). See also the information regarding\n",
      "our stock options and ESPP in Note 11 to the financial statements included herewith.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">The following table\n",
      "provides our equity compensation plan information as of December 31, 2016. Under these plans, our common stock may be issued upon\n",
      "the exercise of options and purchases under our Employee Stock Purchase Plan (“ESPP”). See also the information regarding\n",
      "our stock options and ESPP in Note 11 to the financial statements included herewith.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0; text-align: justify; text-indent: 0.5in\">The Company accounts for\n",
      "stock-based compensation related to grants of stock options, restricted stock awards and purchases under its Employee Stock Purchase\n",
      "Plan (the “ESPP”) at fair value. The Company recognizes compensation expense related to such awards on a straight-line\n",
      "basis over the requisite service period (generally the vesting period) of the equity awards that are expected to vest, which typically\n",
      "occurs ratably over periods ranging from six months to four years. See Note 11 for a further discussion on stock-based compensation.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">The expected term of\n",
      "stock options granted was based on the Company’s historical option exercise experience and post-vesting forfeiture experience\n",
      "using the historical expected term from the vesting date, whereas the expected term for purchases under the ESPP was based on the\n",
      "purchase periods included in the offering. The expected volatility was determined using historical volatilities based on stock\n",
      "prices over a look-back period corresponding to the expected term. The risk-free interest rate was determined using the yield available\n",
      "for zero-coupon U.S. Government issues with a remaining term equal to the expected term. The forfeiture rate was determined using\n",
      "historical pre-vesting forfeiture rates since the inception of the plans. The Company has never paid a dividend, and as such, the\n",
      "dividend yield is zero, and the Company does not intend to pay dividends in the foreseeable future.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">In 2013, the Company\n",
      "adopted an Employee Stock Purchase Plan (the “ESPP”), which currently authorizes an aggregate of 3,300,000 shares of\n",
      "common stock to be purchased, and the aggregate amount of shares will continue to increase 5% on each anniversary of its adoption\n",
      "up to a maximum of 4,000,000 shares. The number of authorized shares and the maximum number of shares both include an increase\n",
      "of 1,000,000 shares approved at the Company’s 2016 annual meeting of stockholders. The ESPP allows employees to purchase\n",
      "shares of common stock of the Company at each purchase date through payroll deductions of up to a maximum of 15% of their compensation,\n",
      "at 85% of the lesser of the market price of the shares at the time of purchase or the market price on the beginning date of an\n",
      "option period (or, if later, the date during the option period when the employee was first eligible to participate). At December\n",
      "31, 2016, there were 1,636,938 shares available for issuance under the ESPP.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">In 2013, the Company\n",
      "adopted an Employee Stock Purchase Plan (the “ESPP”), which currently authorizes an aggregate of 3,300,000 shares of\n",
      "common stock to be purchased, and the aggregate amount of shares will continue to increase 5% on each anniversary of its adoption\n",
      "up to a maximum of 4,000,000 shares. The number of authorized shares and the maximum number of shares both include an increase\n",
      "of 1,000,000 shares approved at the Company’s 2016 annual meeting of stockholders. The ESPP allows employees to purchase\n",
      "shares of common stock of the Company at each purchase date through payroll deductions of up to a maximum of 15% of their compensation,\n",
      "at 85% of the lesser of the market price of the shares at the time of purchase or the market price on the beginning date of an\n",
      "option period (or, if later, the date during the option period when the employee was first eligible to participate). At December\n",
      "31, 2016, there were 1,636,938 shares available for issuance under the ESPP.</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0; text-align: justify; text-indent: 0.5in\">The ESPP is considered\n",
      "compensatory for financial reporting purposes. As such, the fair value of ESPP shares was estimated at the date of grant using\n",
      "the Black-Scholes option-pricing model with the following assumptions:</p>\n",
      "<p style=\"font: 10pt Times New Roman, Times, Serif; margin: 0pt 0; text-align: justify; text-indent: 0.5in\">As of December 31,\n",
      "2016, which is prior to the adoption of ASU 2016-09 (see Note 3), there was approximately $43.6 million of total unrecognized compensation\n",
      "expense (net of estimated forfeitures) related to unvested stock options, ESPP and restricted stock awards. This unrecognized non-cash\n",
      "compensation expense is expected to be recognized over a weighted-average period of 1.5 years, and will be allocated between research\n",
      "and development and general and administrative expenses accordingly. This estimate does not include the impact of other possible\n",
      "stock-based awards that may be made during future periods.</p>\n",
      "<p style=\"margin-left:2.00em; text-indent:-1.00em\"><font size=\"1\" style=\"font-family:Times New Roman\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin-left:2.00em; text-indent:-1.00em\"><font size=\"1\" style=\"font-family:Times New Roman\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin-left:2.00em; text-indent:-1.00em\"><font size=\"1\" style=\"font-family:Times New Roman\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin-top:12px;margin-bottom:0px; text-indent:4%\"><font size=\"2\" style=\"font-family:Times New Roman\">In May 2009, the Companys shareholders approved the 2009 Employee Stock Purchase Plan under which eligible employees may\n",
      "contribute up to 15% of their earnings toward the quarterly purchase of the Companys common stock. The plan makes available 0.9 million shares of the Companys common stock, which includes the remaining shares available under the\n",
      "1996 Employee Stock Purchase Plan. As of December 31, 2016, 1.4 million shares have been issued under both the 2009 and 1996 Employee Stock Purchase Plans. Each plan period lasts three months beginning on January 1, April 1,\n",
      "July 1 and October 1 of each year. The purchase price for each share of stock is the lesser of 90% of the market price on the first day of the plan period or 100% of the market price on the last day of the plan period. Stock-based\n",
      "compensation expense related to this plan was $1 million for each of the years ended December 31, 2016, 2015 and 2014, respectively. </font></p>\n",
      "<p style=\"margin-top:0pt; margin-bottom:0pt\"><font style=\"font-family:Times New Roman;font-size:10pt;margin-left:0px;\">In May 2009, the Company's shareholders approved the 2009 Employee Stock Purchase Plan under which eligible employees may contribute up to 15% of their earnings toward the quarterly purchase of the Company's common stock. The plan makes </font><font style=\"font-family:Times New Roman;font-size:10pt;\">available 0.9 million shares of the Company's common stock, which includes the remaining shares available under the 1996 Employee Stock Purchase Plan. As of December 31, 2016</font><font style=\"font-family:Times New Roman;font-size:10pt;\">, 1.4</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> million shares have been issued under both the 2009 and 1996 Employee Stock Purchase Plans. Each plan period lasts three</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> months beginning on January 1, April 1, July 1 and October 1 of each year. </font><font style=\"font-family:Times New Roman;font-size:10pt;\">The purchase price for each share of stock is the lesser of 90% of the market price on the first day of the plan period or 100% of </font><font style=\"font-family:Times New Roman;font-size:10pt;\">the market price on the last day of the plan period.</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> Stock-based compensation expense related to this plan was </font><font style=\"font-family:Times New Roman;font-size:10pt;\">$</font><font style=\"font-family:Times New Roman;font-size:10pt;\">1</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> million</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> </font><font style=\"font-family:Times New Roman;font-size:10pt;\">for </font><font style=\"font-family:Times New Roman;font-size:10pt;\">each of </font><font style=\"font-family:Times New Roman;font-size:10pt;\">the years ended</font><font style=\"font-family:Times New Roman;font-size:10pt;\"> December 31, 2016</font><font style=\"font-family:Times New Roman;font-size:10pt;\">, 2015 and 2014, respectively.</font></p>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Employee Stock Purchase Plan (ESPP) [Abstract]</p>\n",
      "<p>Employee Stock Purchase Plan (ESPP) [Abstract]</p>\n",
      "<p style=\"margin:0pt 0pt 0pt 12pt;color:#000000;font-family:Times New Roman,Times,serif;font-size: 7pt;\">\n",
      "<font style=\"display:inline;color:#000000;font-size:7pt;\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin:0pt 0pt 0pt 12pt;color:#000000;font-family:Times New Roman,Times,serif;font-size: 7pt;\">\n",
      "<font style=\"display:inline;color:#000000;font-size:7pt;\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin:0pt 0pt 0pt 12pt;color:#000000;font-family:Times New Roman,Times,serif;font-size: 7pt;\">\n",
      "<font style=\"display:inline;color:#000000;font-size:7pt;\">Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin:0pt;color:#000000;font-family:Times New Roman,Times,serif;font-size: 8pt;\">\n",
      "<font style=\"display:inline;color:#000000;font-size:8pt;\">Net proceeds from Class A common stock options exercised and stock issued under the Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin:0pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-weight:bold;font-style:italic;font-size:10pt;\">Employee Stock Purchase Plan</font>\n",
      "</p>\n",
      "<p style=\"margin:0pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-size:10pt;\">Our employees participate in the DISH Network employee stock purchase plan (the “ESPP”), in which we are authorized to issue up to 2.8 million shares of Class A common stock.  At December 31, 2016, we had 1.0 million shares of Class A common stock which remain available for issuance under the ESPP.  Substantially all full-time employees who have been employed by us for at least one calendar quarter are eligible to participate in the ESPP.  Employee stock purchases are made through payroll deductions.  Under the terms of the ESPP, employees may not deduct an amount which would permit such employee to purchase our capital stock under all of our stock purchase plans at a rate which would exceed $25,000 in fair value of capital stock in any one year.  The purchase price of the stock is 85% of the closing price of the Class A common stock on the last business day of each calendar quarter in which such shares of Class A common stock are deemed sold to an employee under the ESPP.  During the years ended December 31, 2016, 2015 and 2014, employee purchases of Class A common stock through the ESPP totaled approximately 0.2 million, 0.1 million and 0.1 million shares, respectively.</font>\n",
      "</p>\n",
      "<p style=\"margin:0pt;line-height:11pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-size:10pt;\">Amended and Restated 1997 Employee Stock Purchase Plan;</font></p>\n",
      "<p style=\"margin:0pt;line-height:11pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-size:10pt;\">1997 Employee Stock Purchase Plan</font></p>\n",
      "<p style=\"margin:0pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-weight:bold;font-style:italic;font-size:10pt;\">Employee Stock Purchase Plan</font>\n",
      "</p>\n",
      "<p style=\"margin:0pt;font-family:Times New Roman,Times,serif;font-size: 10pt;\">\n",
      "<font style=\"display:inline;font-size:10pt;\">Our employees participate in the DISH Network employee stock purchase plan (the “ESPP”), in which we are authorized to issue up to 2.8 million shares of Class A common stock.  At December 31, 2016, we had 1.0 million shares of Class A common stock which remain available for issuance under the ESPP.  Substantially all full-time employees who have been employed by us for at least one calendar quarter are eligible to participate in the ESPP.  Employee stock purchases are made through payroll deductions.  Under the terms of the ESPP, employees may not deduct an amount which would permit such employee to purchase our capital stock under all of our stock purchase plans at a rate which would exceed $25,000 in fair value of capital stock in any one year.  The purchase price of the stock is 85% of the closing price of the Class A common stock on the last business day of each calendar quarter in which such shares of Class A common stock are deemed sold to an employee under the ESPP.  During the years ended December 31, 2016, 2015 and 2014, employee purchases of Class A common stock through the ESPP totaled approximately 0.2 million, 0.1 million and 0.1 million shares, respectively.</font>\n",
      "</p>\n",
      "<p>Employee Stock Purchase Plan maximum fair value of common stock permitted to be purchased per annum.</p>\n",
      "<p>Employee Stock Purchase Plan minimum requisite service period.</p>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-728c00a15298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mkeywordTF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed (src\\lxml\\lxml.etree.c:113759)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed (src\\lxml\\lxml.etree.c:113632)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult (src\\lxml\\lxml.etree.c:130478)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult (src\\lxml\\lxml.etree.c:130221)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\lxml.etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored (src\\lxml\\lxml.etree.c:12064)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs (src\\lxml\\lxml.etree.c:122699)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart (src\\lxml\\lxml.etree.c:122896)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msrc\\lxml\\parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart (src\\lxml\\lxml.etree.c:129218)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         tag = Tag(self, self.builder, name, namespace, nsprefix, attrs,\n\u001b[1;32m--> 465\u001b[1;33m                   self.currentTag, self._most_recent_element)\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml)\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdata_list_attributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m                 attrs = builder._replace_cdata_list_attribute_values(\n\u001b[1;32m--> 842\u001b[1;33m                     self.name, attrs)\n\u001b[0m\u001b[0;32m    843\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py\u001b[0m in \u001b[0;36m_replace_cdata_list_attribute_values\u001b[1;34m(self, tag_name, attrs)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 tag_name.lower(), None)\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muniversal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtag_specific\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtag_specific\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m                     \u001b[1;31m# We have a \"class\"-type attribute whose string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                     \u001b[1;31m# value is a whitespace-separated list of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for url in x['hyperLink']:\n",
    "    r=requests.get(url)\n",
    "    data=r.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    keywordTF = False\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        for z in keywords:\n",
    "            if z in paragraph.text:\n",
    "                print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.40       Henry Schein, Inc. 2004 Employee S...\n",
       "1      The following table\\nprovides our equity compe...\n",
       "2      The following table\\nprovides our equity compe...\n",
       "3      The Company accounts for\\nstock-based compensa...\n",
       "4      The expected term of\\nstock options granted wa...\n",
       "5      In 2013, the Company\\nadopted an Employee Stoc...\n",
       "6      In 2013, the Company\\nadopted an Employee Stoc...\n",
       "7      The ESPP is considered\\ncompensatory for finan...\n",
       "8      As of December 31,\\n2016, which is prior to th...\n",
       "9                           Employee Stock Purchase Plan\n",
       "10                          Employee Stock Purchase Plan\n",
       "11                          Employee Stock Purchase Plan\n",
       "12     In May 2009, the Companys shareholders approv...\n",
       "13     In May 2009, the Company's shareholders approv...\n",
       "14        Employee Stock Purchase Plan (ESPP) [Abstract]\n",
       "15        Employee Stock Purchase Plan (ESPP) [Abstract]\n",
       "16                        \\nEmployee Stock Purchase Plan\n",
       "17                        \\nEmployee Stock Purchase Plan\n",
       "18                        \\nEmployee Stock Purchase Plan\n",
       "19     \\nNet proceeds from Class A common stock optio...\n",
       "20                      \\nEmployee Stock Purchase Plan\\n\n",
       "21     \\nOur employees participate in the DISH Networ...\n",
       "22     \\nAmended and Restated 1997 Employee Stock Pur...\n",
       "23                   \\n1997 Employee Stock Purchase Plan\n",
       "24                      \\nEmployee Stock Purchase Plan\\n\n",
       "25     \\nOur employees participate in the DISH Networ...\n",
       "26     Employee Stock Purchase Plan maximum fair valu...\n",
       "27     Employee Stock Purchase Plan minimum requisite...\n",
       "28     We measure and recognize compensation expense ...\n",
       "29     We measure and recognize compensation expense ...\n",
       "                             ...                        \n",
       "497    7(N])'1LJQ!\\Z_X)._\\HLOV:?^R5>%_P#T\\nMT6M>_P!)I...\n",
       "498    The Company uses the Black-Scholes option-pric...\n",
       "499    During 2016 the Companys Board of Directors a...\n",
       "500    During 2016 the Companys Board of Directors a...\n",
       "501    At December 31, 2016, the Company has 6.3 mill...\n",
       "502                         Employee Stock Purchase Plan\n",
       "503    The Company received cash proceeds of $1.2 mil...\n",
       "504    ·      the Registration Statement (Form S-8 No...\n",
       "505    \\nThe Company uses the Black-Scholes option-pr...\n",
       "506    \\nDuring 2016 the Company’s Board of Directors...\n",
       "507    \\nDuring 2016 the Company’s Board of Directors...\n",
       "508    \\nAt December 31, 2016, the Company has 6.3 mi...\n",
       "509                     \\nEmployee Stock Purchase Plan\\n\n",
       "510    \\nThe Company received cash proceeds of $1.2 m...\n",
       "511    \\nThe Company uses the Black-Scholes option-pr...\n",
       "512    Maximum contribution amount per employee to ESPP.\n",
       "513    X$3;+3I/J,727\\1]\\&',_J\"SK1GDGH_\\+U!+ P04    \" ...\n",
       "514    X$3;+3I/J,727\\1]\\&',_J\"SK1GDGH_\\+U!+ P04    \" ...\n",
       "515    <8%.E('(P7!1U $6/0 HHB[%:800K@)6=L>/\"BTW;,A\\4Q...\n",
       "516    <8%.E('(P7!1U $6/0 HHB[%:800K@)6=L>/\"BTW;,A\\4Q...\n",
       "517    @XD),A-31 89@:E;O\\A-[,\"+G%TEK5LXK8%0YU0VTHF:MQ...\n",
       "518    @XD),A-31 89@:E;O\\A-[,\"+G%TEK5LXK8%0YU0VTHF:MQ...\n",
       "519    5DJ)P,D1/WY&3#\\nM?2 #DO?D8+ 8LI&_.D?EY(B $'^ P...\n",
       "520    5DJ)P,D1/WY&3#\\nM?2 #DO?D8+ 8LI&_.D?EY(B $'^ P...\n",
       "521    9_F@,[48#O@!?P-\\6P\"5FJ-/_$+\"'L+@]& ?):(Q*N/WRF...\n",
       "522    9_F@,[48#O@!?P-\\6P\"5FJ-/_$+\"'L+@]& ?):(Q*N/WRF...\n",
       "523    T1OC5J2VJ$/_(\\nMQS1AYL&8%*-R-\"LRJH'G\",)ACCE*9V...\n",
       "524    T1OC5J2VJ$/_(\\nMQS1AYL&8%*-R-\"LRJH'G\",)ACCE*9V...\n",
       "525    GYGL@ ]R.=^LQ?V+D@P_PD6Z$C0#QR-\\1FL4TK*K1H2]@F...\n",
       "526    GYGL@ ]R.=^LQ?V+D@P_PD6Z$C0#QR-\\1FL4TK*K1H2]@F...\n",
       "Name: 0, Length: 527, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    670\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 672\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    381\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                                 \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_baseclass_reprs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'<'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__unicode__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, pretty_print, eventual_encoding, formatter)\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mindent_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         return prefix + super(BeautifulSoup, self).decode(\n\u001b[1;32m--> 501\u001b[1;33m             indent_level, eventual_encoding, formatter)\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;31m# Alias to make it easier to type import: 'from bs4 import _soup'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, indent_level, eventual_encoding, formatter)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mindent_contents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         contents = self.decode_contents(\n\u001b[1;32m-> 1180\u001b[1;33m             indent_contents, eventual_encoding, formatter)\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mdecode_contents\u001b[1;34m(self, indent_level, eventual_encoding, formatter)\u001b[0m\n\u001b[0;32m   1247\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m                 s.append(c.decode(indent_level, eventual_encoding,\n\u001b[1;32m-> 1249\u001b[1;33m                                   formatter))\n\u001b[0m\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent_level\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pre'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "... last 2 frames repeated, from the frame below ...\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, indent_level, eventual_encoding, formatter)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mindent_contents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         contents = self.decode_contents(\n\u001b[1;32m-> 1180\u001b[1;33m             indent_contents, eventual_encoding, formatter)\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 out of 21 dont have a keyword\n",
      "8 have keywords out of 21\n"
     ]
    }
   ],
   "source": [
    "# textList = []\n",
    "# count = 0\n",
    "# count1 = 0\n",
    "# for i in documents:\n",
    "#     keywordTF = False\n",
    "#     for paragraph in i.find_all('p'):\n",
    "#         for z in keywords:\n",
    "#             if z in paragraph.text:\n",
    "#                 textList.append(paragraph.text)\n",
    "#                 keywordTF = True\n",
    "#     if keywordTF == False:\n",
    "#         count +=1\n",
    "#     else:\n",
    "#         count1 +=1\n",
    "\n",
    "# print(str(count) + ' out of ' + str(len(documents)) + ' dont have a keyword')\n",
    "# print(str(count1) + ' have keywords out of ' + str(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Employee Stock Purchase Plan' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-58a65ff03dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myour_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlist_of_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myour_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Employee Stock Purchase Plan'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnext_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_of_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist_of_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Employee Stock Purchase Plan'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'Employee Stock Purchase Plan' is not in list"
     ]
    }
   ],
   "source": [
    "your_string = textList[0]\n",
    "list_of_words = your_string.split('Employee Stock Purchase Plan')\n",
    "next_word = list_of_words[list_of_words.index('Employee Stock Purchase Plan') + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textList = []\n",
    "count = 0\n",
    "count1 = 0\n",
    "for i in documents[2]:\n",
    "    keywordTF = False\n",
    "    for paragraph in i.find_all('p'):\n",
    "        for z in keywords:\n",
    "            if z in paragraph.text:\n",
    "                textList.append(paragraph.text)\n",
    "                keywordTF = True\n",
    "    if keywordTF == False:\n",
    "        count +=1\n",
    "    else:\n",
    "        count1 +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW CODE IS DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'textLis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-4e477b3a8e0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextLis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'textLis' is not defined"
     ]
    }
   ],
   "source": [
    "len(textLis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# listOf10ks = []\n",
    "# actual10Ks = []\n",
    "# linkTo10K = ''\n",
    "# mainurl = \"https://www.sec.gov\"\n",
    "# count = 1\n",
    "\n",
    "# cikList = ['0001466593', '0001121484']\n",
    "# for cik in cikList:\n",
    "#     url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=\" + cik + \"&owner=include&count=40\"\n",
    "#     r=requests.get(url)\n",
    "#     data=r.text\n",
    "#     soup = BeautifulSoup(data, 'lxml')\n",
    "#     for links in soup.find_all('tr'):\n",
    "#         if '10-K' in links.text:\n",
    "#             for element in links.find_all('a'):\n",
    "#                 if element.text == '\\xa0Documents':\n",
    "#                     listOf10ks = element.get('href')\n",
    "#                     r=requests.get(mainurl + listOf10ks)\n",
    "#                     data=r.text\n",
    "#                     soup = BeautifulSoup(data, 'lxml')\n",
    "#                     for links in soup.find_all('tr'):\n",
    "#                         if '10-K' in links.text:\n",
    "#                             for element in links.find_all('a'):\n",
    "#                                 print(element.text)\n",
    "#                                 linkTo10K = element.get('href')\n",
    "#                                 r=requests.get(mainurl + linkTo10K)\n",
    "#                                 data=r.text\n",
    "#                                 soup = BeautifulSoup(data, 'lxml')\n",
    "#                                 actual10Ks.append(soup)\n",
    "#                                 print(str(count) + ' 10K is appended')\n",
    "#                                 count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     for links in soup.find_all('tr'):\n",
    "#         if '10-K' in links.text:\n",
    "#             for element in links.find_all('a'):\n",
    "#                 if element.text == '\\xa0Documents':\n",
    "#                     listOf10ks = element.get('href')\n",
    "#                     r=requests.get(mainurl + listOf10ks)\n",
    "#                     data=r.text\n",
    "#                     soup = BeautifulSoup(data, 'lxml')\n",
    "#                     for links in soup.find_all('tr'):\n",
    "#                         if '10-K' in links.text:\n",
    "#                             for element in links.find_all('a'):\n",
    "#                                 print(element.text)\n",
    "#                                 linkTo10K = element.get('href')\n",
    "#                                 r=requests.get(mainurl + linkTo10K)\n",
    "#                                 data=r.text\n",
    "#                                 soup = BeautifulSoup(data, 'lxml')\n",
    "#                                 actual10Ks.append(soup)\n",
    "#                                 print(str(count) + ' 10K is appended')\n",
    "#                                 count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.chdir('C:\\\\Users\\\\Cody\\\\Documents\\\\2017-2018 School Year\\\\Semester 2\\\\CIS440')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('master.idx', 'rb') as f:\n",
    "#     data = f.read()\n",
    "\n",
    "# data =data.decode(\"utf-8\")\n",
    "# data = data.split('|')\n",
    "# data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# companies = []\n",
    "# forms = []\n",
    "# dateFiled = []\n",
    "# hyperLink = []\n",
    "# totalData = pd.DataFrame()\n",
    "# allTheCorrectData = pd.DataFrame()\n",
    "\n",
    "\n",
    "# data =data.decode(\"utf-8\")\n",
    "# data = data.split('|')\n",
    "# data = data[1:]\n",
    "\n",
    "# count = 0\n",
    "# while count < len(data):\n",
    "#     companies.append(data[count])\n",
    "#     count+=4\n",
    "    \n",
    "# count = 1\n",
    "# while count < len(data):\n",
    "#     forms.append(data[count])\n",
    "#     count+=4\n",
    "    \n",
    "# count = 2\n",
    "# while count < len(data):\n",
    "#     dateFiled.append(data[count])\n",
    "#     count+=4\n",
    "    \n",
    "# count = 3\n",
    "# while count < len(data):\n",
    "#     hyperLink.append(data[count])\n",
    "#     count+=4\n",
    "    \n",
    "# masterData = pd.DataFrame({'Company Names' : companies, 'Forms':forms,'Date Filed':dateFiled,'hyperLink':hyperLink})\n",
    "# masterData = masterData.iloc[1:,]\n",
    "# correctData = masterData[masterData['Forms'] == '10-K']\n",
    "\n",
    "# totalData = totalData.append(masterData)\n",
    "# allTheCorrectData = allTheCorrectData.append(correctData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataUrls = []\n",
    "#                     for i in correctList:\n",
    "#                         dataUrls.append('https://www.sec.gov/Archives/' + i)\n",
    "                    \n",
    "#                     documents = []\n",
    "#                     count = 1\n",
    "#                     for url in dataUrls:\n",
    "#                         r=requests.get(url)\n",
    "#                         data=r.text\n",
    "#                         soup = BeautifulSoup(data, 'lxml')\n",
    "#                         documents.append(soup)\n",
    "#                         print('document' + str(count) + 'appended')\n",
    "#                         count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from io import BytesIO\n",
    "# from urllib.request import urlopen\n",
    "# from zipfile import ZipFile\n",
    "\n",
    "# master = \"master.zip\"\n",
    "# r=requests.get(newNewUrls[95])\n",
    "# data=r.text\n",
    "# soup = BeautifulSoup(data, 'lxml')\n",
    "# for tag in soup.find_all('a'):\n",
    "#     if tag.text == master:\n",
    "#         zipurl = newNewUrls[95] + tag.text\n",
    "#         with urlopen(zipurl) as zipresp:\n",
    "#             with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "#                 zfile.extractall('C:\\\\Users\\\\Cody\\\\Documents\\\\2017-2018 School Year\\\\Semester 2\\\\CIS440\\\\index files')\n",
    "#                 zfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
